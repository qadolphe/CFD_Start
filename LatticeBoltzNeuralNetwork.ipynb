{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj-8aX59BhZk",
        "outputId": "2ba8bee3-7ed8-439a-82eb-bb2930d1e643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import save_model, load_model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ORYoalOHBkA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "with h5py.File('/content/drive/MyDrive/Colab Notebooks/data.h5', 'r') as f:\n",
        "    velocity_data = f['velocity'][:]\n",
        "    density_data = f['density'][:]\n",
        "    boundary_data = f['boundary'][:]\n",
        "\n",
        "velocity_data = np.expand_dims(velocity_data, axis=-1)  # Shape: (4002, 100, 400, 1)\n",
        "density_data = np.expand_dims(density_data, axis=-1)    # Shape: (4002, 100, 400, 1)\n",
        "boundary_data = np.expand_dims(boundary_data, axis=-1)  # Shape: (4002, 100, 400, 1)\n",
        "\n",
        "print(\"Velocity Data Shape:\", velocity_data.shape)\n",
        "print(\"Density Data Shape:\", density_data.shape)\n",
        "print(\"Boundary Data Shape:\", boundary_data.shape)"
      ],
      "metadata": {
        "id": "lz9lUf9KBh2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8ff1c44-482b-405d-ad27-fecec66c435f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Velocity Data Shape: (8004, 100, 400, 1)\n",
            "Density Data Shape: (8004, 100, 400, 1)\n",
            "Boundary Data Shape: (8004, 100, 400, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the data to 2D for scaling\n",
        "num_samples = velocity_data.shape[0]\n",
        "H, W = velocity_data.shape[1], velocity_data.shape[2]\n",
        "velocity_data_2d = velocity_data.reshape(num_samples, -1)\n",
        "density_data_2d = density_data.reshape(num_samples, -1)\n",
        "boundary_data_2d = boundary_data.reshape(num_samples, -1)\n",
        "\n",
        "# Create and fit scalers\n",
        "velocity_scaler = StandardScaler().fit(velocity_data_2d)\n",
        "density_scaler = StandardScaler().fit(density_data_2d)\n",
        "boundary_scaler = StandardScaler().fit(boundary_data_2d)\n",
        "\n",
        "# Transform the data\n",
        "velocity_data_scaled = velocity_scaler.transform(velocity_data_2d).reshape(num_samples, H, W)\n",
        "density_data_scaled = density_scaler.transform(density_data_2d).reshape(num_samples, H, W)\n",
        "boundary_data_scaled = boundary_scaler.transform(boundary_data_2d).reshape(num_samples, H, W)\n",
        "\n",
        "# Similarly, you should also fit and transform the target data\n"
      ],
      "metadata": {
        "id": "9wQND2D7MCK4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1A2uh38fFzti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine inputs: velocity, density, and boundary\n",
        "X = np.concatenate((velocity_data_scaled, density_data_scaled, boundary_data_scaled), axis=-1)  # Shape: (4002, 100, 400, 3)\n",
        "# Targets: velocity and density\n",
        "y = np.concatenate((velocity_data_scaled, density_data_scaled), axis=-1)  # Shape: (4002, 100, 400, 2)\n",
        "\n",
        "X = np.concatenate((velocity_data_scaled[:-1], density_data_scaled[:-1], boundary_data_scaled[:-1]), axis=-1)  # Exclude last time step\n",
        "y = np.concatenate((velocity_data_scaled[1:], density_data_scaled[1:]), axis=-1)  # Exclude first time step\n"
      ],
      "metadata": {
        "id": "CHOexZ3LMrS8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsKfLDmlGfys",
        "outputId": "7633f469-730c-45c8-c9d7-1255108e868d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8003, 100, 400, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine inputs: velocity, density, and boundary\n",
        "X = np.concatenate((velocity_data, density_data, boundary_data), axis=-1)  # Shape: (4002, 100, 400, 3)\n",
        "# Targets: velocity and density\n",
        "y = np.concatenate((velocity_data, density_data), axis=-1)  # Shape: (4002, 100, 400, 2)\n",
        "\n",
        "X = np.concatenate((velocity_data[:-1], density_data[:-1], boundary_data[:-1]), axis=-1)  # Exclude last time step\n",
        "y = np.concatenate((velocity_data[1:], density_data[1:]), axis=-1)  # Exclude first time step\n"
      ],
      "metadata": {
        "id": "mPK3JGnYNNBD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "IgxU-t2XMEp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)"
      ],
      "metadata": {
        "id": "d2lzXEAbOnup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a302252d-ed52-4533-a76b-ecddcdc819ac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5602, 100, 400, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN architecture\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(y_train.shape[1] * y_train.shape[2] * y_train.shape[3], activation='linear'),  # Output layer\n",
        "    layers.Reshape((y_train.shape[1], y_train.shape[2], y_train.shape[3]))  # Adjust based on your target shape\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "FIpqAA37CPTz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "3be98b7e-de73-4734-f0ec-36338a565bc5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "tuple index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5eff875e162e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define the CNN architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model = models.Sequential([\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)])\n",
        "\n"
      ],
      "metadata": {
        "id": "91uQyhDfQRbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {test_loss}, Test MAE: {test_mae}\")\n",
        "\n",
        "model.save('velocity_density_predictor.keras')"
      ],
      "metadata": {
        "id": "Yn83mCxXQX7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "H5nP6j86igvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "print('Model size: %dKB' % (len(tflite_model) / 1024))\n",
        "\n",
        "with open('velocity_density_predictorCyl.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "2v83pBXER4bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelT = load_model('velocity_density_predictor.keras')"
      ],
      "metadata": {
        "id": "OcsLrpC2gxFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.animation import FuncAnimation, FFMpegWriter\n",
        "from matplotlib.widgets import Button"
      ],
      "metadata": {
        "id": "PeMCe8RRlhnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NEXT Thing"
      ],
      "metadata": {
        "id": "apqxiycqley3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def distance(x1,y1,x2,y2):\n",
        "    return np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
        "\n",
        "def toggle_visibility(event):\n",
        "    if vorticity_img.get_visible():\n",
        "        vorticity_img.set_visible(False)\n",
        "        velocity_img.set_visible(True)\n",
        "    else:\n",
        "        vorticity_img.set_visible(True)\n",
        "        velocity_img.set_visible(False)\n",
        "    fig.canvas.draw_idle()\n",
        "\n",
        "# Simulation parameters\n",
        "Nx = 400    # resolution x-dir\n",
        "Ny = 100    # resolution y-dir\n",
        "rho0 = 100  # average density\n",
        "tau = 0.6   # collision timescale\n",
        "Nt = 1000   # number of timesteps\n",
        "plotRealTime = True  # switch on for plotting as the simulation goes along\n",
        "\n",
        "# Lattice speeds / weights\n",
        "NL = 9\n",
        "idxs = np.arange(NL)\n",
        "cxs = np.array([0, 0, 1, 1, 1, 0, -1, -1, -1])\n",
        "cys = np.array([0, 1, 1, 0, -1, -1, -1, 0, 1])\n",
        "weights = np.array([4/9, 1/9, 1/36, 1/9, 1/36, 1/9, 1/36, 1/9, 1/36])\n",
        "\n",
        "# Initial Conditions\n",
        "F = np.ones((Ny, Nx, NL))  # * rho0 / NL\n",
        "F += 0.01 * np.random.randn(Ny, Nx, NL)  # Perturb initial state\n",
        "F[:, :, 3] += 2.3 #2 * (1 + 0.2 * np.cos(2 * np.pi * X / Nx * 4))\n",
        "\n",
        "rho = np.sum(F, 2)\n",
        "for i in idxs:\n",
        "    F[:, :, i] *= rho0 / rho\n",
        "\n",
        "# Cylinder boundary\n",
        "circleX, circleY = Nx//4, Ny//2\n",
        "radius = 13\n",
        "objects = np.full((Ny,Nx),False)\n",
        "for y in range(Ny):\n",
        "    for x in range(Nx):\n",
        "        if distance(circleX,circleY,x,y) < radius: objects[y][x] = True\n",
        "\n",
        "\n",
        "# Prep figure\n",
        "fig, ax = plt.subplots(figsize=(8, 4), dpi=80)\n",
        "ax.set_aspect('equal')\n",
        "ax.get_xaxis().set_visible(False)\n",
        "ax.get_yaxis().set_visible(False)\n",
        "\n",
        "# Initialize the plot with empty data\n",
        "vorticity_img = ax.imshow(np.zeros((Ny, Nx)), cmap='bwr', animated=True)\n",
        "velocity_img = ax.imshow(np.zeros((Ny, Nx)), cmap='viridis', animated=True)\n",
        "cylinder_img = ax.imshow(~objects, cmap='gray', alpha=0.3, animated=True)\n",
        "\n",
        "velocity_img.set_visible(False)\n",
        "vorticity_img.set_visible(True)"
      ],
      "metadata": {
        "id": "cO-Hg4Nrg8qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update(it):\n",
        "    global F\n",
        "\n",
        "    # Prepare input for the model\n",
        "    rho = np.sum(F, 2)\n",
        "    ux = np.sum(F * cxs, 2) / rho\n",
        "    uy = np.sum(F * cys, 2) / rho\n",
        "    velocity = np.sqrt(ux**2 + uy**2)\n",
        "\n",
        "    # Reshape input data for model\n",
        "    model_input = np.stack([velocity, rho, objects.astype(np.float32)], axis=-1)\n",
        "    model_input = np.expand_dims(model_input, axis=0)  # Add batch dimension\n",
        "    # Predict the next state\n",
        "    prediction = modelT.predict(model_input)\n",
        "\n",
        "    # Extract predicted velocity and density\n",
        "    predicted_velocity = prediction[0, :, :, 0]  # Adjust according to your model's output shape\n",
        "    predicted_density = prediction[0, :, :, 1]  # Adjust according to your model's output shape\n",
        "\n",
        "    # Update the current state with the predicted state\n",
        "    velocity_img.set_array(predicted_velocity)\n",
        "    velocity_img.set_clim(0, np.max(predicted_velocity))\n",
        "\n",
        "    vorticity = (np.roll(ux, -1, axis=0) - np.roll(ux, 1, axis=0)) - (np.roll(uy, -1, axis=1) - np.roll(uy, 1, axis=1))\n",
        "    vorticity[objects] = np.nan\n",
        "    vorticity = np.ma.array(vorticity, mask=objects)\n",
        "\n",
        "    vorticity_img.set_array(vorticity)\n",
        "    vorticity_img.set_clim(-0.1, 0.1)\n",
        "\n",
        "    return velocity_img, vorticity_img, cylinder_img"
      ],
      "metadata": {
        "id": "Nav4opAIllPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def updateOG(it):\n",
        "    \"\"\" Update function for animation \"\"\"\n",
        "    global F\n",
        "\n",
        "    F[:, -1, [6,7,8]] = F[:, -2, [6,7,8]]\n",
        "    F[:, 0, [2,3,4]] = F[:, 1, [2,3,4]]\n",
        "    # Drift\n",
        "    for i, cx, cy in zip(idxs, cxs, cys):\n",
        "        F[:, :, i] = np.roll(F[:, :, i], cx, axis=1)  # Shift by cx in x-direction\n",
        "        F[:, :, i] = np.roll(F[:, :, i], cy, axis=0)  # Shift by cy in y-direction\n",
        "\n",
        "    # Set reflective boundaries\n",
        "    bndryF = F[objects, :]\n",
        "    bndryF = bndryF[:, [0, 5, 6, 7, 8, 1, 2, 3, 4]]\n",
        "\n",
        "    # Calculate fluid variables\n",
        "    rho = np.sum(F, 2)\n",
        "    ux = np.sum(F * cxs, 2) / rho\n",
        "    uy = np.sum(F * cys, 2) / rho\n",
        "\n",
        "    # Apply Collision\n",
        "    Feq = np.zeros(F.shape)\n",
        "    for i, cx, cy, w in zip(idxs, cxs, cys, weights):\n",
        "        Feq[:, :, i] = rho * w * (1 + 3 * (cx * ux + cy * uy) + 9 * (cx * ux + cy * uy)**2 / 2 - 3 * (ux**2 + uy**2) / 2)\n",
        "\n",
        "    F += -(1.0 / tau) * (F - Feq)\n",
        "\n",
        "    # Apply boundary\n",
        "    F[objects, :] = bndryF\n",
        "    ux[objects] = 0\n",
        "    uy[objects] = 0\n",
        "\n",
        "    velocity = np.sqrt(ux**2+uy**2)\n",
        "    velocity_img.set_array(velocity)\n",
        "    velocity_img.set_clim(0, np.max(velocity))\n",
        "\n",
        "    vorticity = (np.roll(ux, -1, axis=0) - np.roll(ux, 1, axis=0)) - (np.roll(uy, -1, axis=1) - np.roll(uy, 1, axis=1))\n",
        "    vorticity[objects] = np.nan\n",
        "    vorticity = np.ma.array(vorticity, mask=objects)\n",
        "\n",
        "    vorticity_img.set_array(vorticity)\n",
        "    vorticity_img.set_clim(-0.1, 0.1)\n",
        "\n",
        "    return velocity_img, vorticity_img, cylinder_img"
      ],
      "metadata": {
        "id": "gYH8nwFrnDWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anim = FuncAnimation(fig, update, frames=range(Nt), interval=1, blit=True, repeat=False)\n"
      ],
      "metadata": {
        "id": "lmYBO-fvmkJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anim.save('animation.mp4', writer='ffmpeg', fps=60)"
      ],
      "metadata": {
        "id": "sDYoF3AdmqEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eRjnCIycmzK6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7xsWzeIYmy-x"
      }
    }
  ]
}